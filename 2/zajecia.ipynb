{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wprowadzenie do sieci neuronowych\n",
    "\n",
    "Organizator: Koło naukowe BioMedicalAI  \n",
    "![biomedical.svg](biomedical.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea i historia sieci neuronowych (30m)\n",
    "Sieci neuronowe są podzbiorem technik maszynowego uczenia, stosowane w obszarach wizji komputerowej, przetwarzania języka naturalnego, generacji tekstu i obrazów itp. Sieć zazyczaj skłąda się z kilku warstw: warstwy wejściowej, N warstw ukrytych oraz warstwy wyjścia. Pomiędzy warstwami stosuje się nieliniowe funkcje aktywancji w celu modelowania nieliniowego zachowania. Sieci trenowane są zazwyczaj z wykorzystaniem mechanizmu propagacji wstecznej, wykorzystującej pochodne funkcji w celu propagowania błedu oraz zmiany parametrów.\n",
    "\n",
    "![\"Schemat sieci neuronowej\"](./The-Fully-Connected-Neural-Network-model-used-in-our-paper_W640.jpg)  \n",
    "*Dumor, Koffi & Li, Yao. (2019). Estimating China’s Trade with Its Partner Countries within the Belt and Road Initiative Using Neural Network Analysis. Sustainability. 11. 1449. 10.3390/su11051449.*\n",
    "\n",
    "### Historia sieci neuronowych\n",
    "Historia sieci neuronowych bardzo mocno splata się z historią psychologii oraz poznania mechanizów stojących za ludzkim postrzeganiem oraz podejmowaniem decyzji.  \n",
    "\n",
    "Koncept sieci neuronowych pojawia się już w 1943r. w artykule \"A logical calculus of the ideas immanent in nervous activity\" W. McCulloch, W. Pitts, gdzie próbowano zamodelować działanie mózgu poprzez proste elementy logiczne.  \n",
    "\n",
    "Dużym osiagnięciem bylo opublikowanie w 1958r. artykułu \"The perceptron: A probabilistic model for information storage and organization in the brain.\" Franka Rosenblatta opisujący system przetwarzania informacji wizyjnej - mark I Perceptron.   \n",
    "System zbudowany był w oparciu o maszynę IBM 704 i składał się z 3 warstw:\n",
    "* sensory units (S-units) - warstwa wejściowa, 20x20 fotodetektorów, gdzie każdy S-unit łączył się losowo z warstwą A-unitów\n",
    "* association units (A-units) - warstwa ukryta składająca się z 512 neuronów, ustawiana ręcznie poprzez odpowiednie ustawienie potencjometrów\n",
    "* response units(R-units) - warstwa wyjścia\n",
    "Badane było wykorzystanie Perceptrona do analizy zdjęć lotniczych i detekcji systemów wojskowych\n",
    "\n",
    "![\"Wykorzystanie systemu Perceptron\"](./perceptron-use.jpg)\n",
    "*By National Museum of the U.S. Navy - 330-PSA-80-60 (USN 710739), Public Domain, https://commons.wikimedia.org/w/index.php?curid=70710209*\n",
    "\n",
    "![\"Schemat opisujący elementy Perceptrona\"](./percpetron-op-man.png)  \n",
    "*By John C. Hay, Albert E. Murray - https://apps.dtic.mil/sti/tr/pdf/AD0236965.pdf, Public Domain, https://commons.wikimedia.org/w/index.php?curid=143176022*\n",
    "\n",
    "![\"Figura z artykułu F. Rosenblatta porównująca działanie ludzkiego mózgu z perceptronem do przetwarzania widzenia.\"](./Organization_of_a_biological_brain_and_a_perceptron.png)  \n",
    "*By Rosenblatt, F. - Rosenblatt, F. The Design of an Intelligent Automaton, Research Reviews, Office of Naval Research. Washington, October 1958, 5-13, Public Domain, https://commons.wikimedia.org/w/index.php?curid=139658945*\n",
    "\n",
    "W 1974 r. Paul Werbos w swojej pracy doktorskiej opisał użycie propagacji wstecznej w celu uczenia sieci neuronowej, natomiast w 1985r. David Rumelhart wraz z  Geoffrey Hintonem oraz Ronald J. Williamsem niezaleznie opisali zastosowanie algorytmu propagacji wstecznej w celu uczenia MLP.\n",
    "\n",
    "Sepp Hochreiter w 1995 r. zaproponował LSTM (long short-term memory) jako rozwiązanie problemu zanikającego gradientu w rekurencyjnych sieciach neuronowych.\n",
    "\n",
    "W 1980 r. Kunihiko Fukushima zaproponowal CNN bazując na badaniach z lat 50-60 opisujących sposób postrzegania przez koty. Warta wspomnienia jest praca Yann LeCun, który w 1989 r. zaproponował sieć LeNet bazującą na CNN do odczytu odręcznego pisma, co spowodowało budowę komercyjnych zastosowań opartych na sieciach neuronowych i CNN.\n",
    "\n",
    "Głębokie uczenie określane jako uczenie wielowarstwowe dużych sieci zaczęło się rozpowszechniać wraz z zastsoowaniem GPU do przyśpieszenia uczenia. W 2009 r. Raina, Madhavan, oraz Andrew Ng pracowali nad sieciami trenowanymi z użyciem GPU. W 2012 r. głęboka sieć AlexNet znacząco poprawiła najwyższy wynik w konkursie ImageNet, co uposzechniło głębokie uczenie.\n",
    "\n",
    "W 2017r. w artykule \"Attention Is All You Need\" Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Lukasz Kaiser, and Illia Polosukhin zaproponowano architekturę transformer, rewolucjonizującą przetwarzanie sekwencji (NLP). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorytm propagacji wstecznej (5m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_tkinter'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmatplotlib\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtk\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m animation\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Pyhton/Kurs-Podstawy-AI/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Developer/Pyhton/Kurs-Podstawy-AI/.venv/lib/python3.13/site-packages/IPython/core/magics/pylab.py:103\u001b[0m, in \u001b[0;36mPylabMagics.matplotlib\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;241m%\u001b[39m _list_matplotlib_backends_and_gui_loops()\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     gui, backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_show_matplotlib_backend(args\u001b[38;5;241m.\u001b[39mgui, backend)\n",
      "File \u001b[0;32m~/Developer/Pyhton/Kurs-Podstawy-AI/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3677\u001b[0m, in \u001b[0;36mInteractiveShell.enable_matplotlib\u001b[0;34m(self, gui)\u001b[0m\n\u001b[1;32m   3673\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWarning: Cannot change to a different GUI toolkit: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   3674\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Using \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (gui, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select))\n\u001b[1;32m   3675\u001b[0m         gui, backend \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mfind_gui_and_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpylab_gui_select)\n\u001b[0;32m-> 3677\u001b[0m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivate_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3679\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib_inline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_inline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_inline_support\n\u001b[1;32m   3681\u001b[0m configure_inline_support(\u001b[38;5;28mself\u001b[39m, backend)\n",
      "File \u001b[0;32m~/Developer/Pyhton/Kurs-Podstawy-AI/.venv/lib/python3.13/site-packages/IPython/core/pylabtools.py:410\u001b[0m, in \u001b[0;36mactivate_matplotlib\u001b[0;34m(backend)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# Due to circular imports, pyplot may be only partially initialised\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m# when this function runs.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# So avoid needing matplotlib attribute-lookup to access pyplot.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[0;32m--> 410\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswitch_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow\u001b[38;5;241m.\u001b[39m_needmain \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;66;03m# We need to detect at runtime whether show() is called by the user.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# For this, we wrap it into a decorator which adds a 'called' flag.\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Pyhton/Kurs-Podstawy-AI/.venv/lib/python3.13/site-packages/matplotlib/pyplot.py:415\u001b[0m, in \u001b[0;36mswitch_backend\u001b[0;34m(newbackend)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# have to escape the switch on access logic\u001b[39;00m\n\u001b[1;32m    413\u001b[0m old_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(rcParams, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackend\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 415\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mbackend_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_backend_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m canvas_class \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mFigureCanvas\n\u001b[1;32m    418\u001b[0m required_framework \u001b[38;5;241m=\u001b[39m canvas_class\u001b[38;5;241m.\u001b[39mrequired_interactive_framework\n",
      "File \u001b[0;32m~/Developer/Pyhton/Kurs-Podstawy-AI/.venv/lib/python3.13/site-packages/matplotlib/backends/registry.py:323\u001b[0m, in \u001b[0;36mBackendRegistry.load_backend_module\u001b[0;34m(self, backend)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;124;03mLoad and return the module containing the specified backend.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    Module containing backend.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    322\u001b[0m module_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend_module_name(backend)\n\u001b[0;32m--> 323\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/importlib/__init__.py:88\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     87\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:1022\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Developer/Pyhton/Kurs-Podstawy-AI/.venv/lib/python3.13/site-packages/matplotlib/backends/backend_tkagg.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _backend_tk\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_agg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasAgg\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_backend_tk\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _BackendTk, FigureCanvasTk\n",
      "File \u001b[0;32m~/Developer/Pyhton/Kurs-Podstawy-AI/.venv/lib/python3.13/site-packages/matplotlib/backends/_backend_tk.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtk\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfiledialog\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfont\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.13/3.13.0_1/Frameworks/Python.framework/Versions/3.13/lib/python3.13/tkinter/__init__.py:38\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtypes\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01m_tkinter\u001b[39;00m \u001b[38;5;66;03m# If this fails your Python may not be configured for Tk\u001b[39;00m\n\u001b[1;32m     39\u001b[0m TclError \u001b[38;5;241m=\u001b[39m _tkinter\u001b[38;5;241m.\u001b[39mTclError\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtkinter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_tkinter'"
     ]
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "n_steps = 100\n",
    "x_lin = np.linspace(-2, 2, 400)\n",
    "y_lin = np.linspace(-2, 2, 400)\n",
    "x, y = np.meshgrid(x_lin, y_lin)\n",
    "positions = np.zeros((n_steps+1, 2))\n",
    "lr = 0.1\n",
    "\n",
    "# Funkcja którą optymalizujemy\n",
    "def func(x, y):\n",
    "    return x**2 - y**2\n",
    "\n",
    "# Nasz model składający się z 2 parametrów\n",
    "theta_x, theta_y = np.random.normal(size=(2))\n",
    "positions[0, 0] = theta_x\n",
    "positions[0, 1] = theta_y\n",
    "\n",
    "for epoch in range(n_steps):\n",
    "    grad_x = 2 * theta_x\n",
    "    grad_y = -2 * theta_y\n",
    "\n",
    "    theta_x -= lr * grad_x\n",
    "    theta_y -= lr * grad_y\n",
    "\n",
    "    positions[epoch+1, 0] = theta_x\n",
    "    positions[epoch+1, 1] = theta_y\n",
    "\n",
    "# Animation of SGD steps\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "scat = ax.scatter(positions[0, 0], positions[0, 1], color=\"red\")\n",
    "line, = ax.plot(positions[0, 0], positions[0, 1], color=\"red\")\n",
    "\n",
    "plt.imshow(func(x, y), extent=[-2, 2, 2, -2])\n",
    "\n",
    "def animate(i):\n",
    "    line.set_data(positions[:i+1, 0], positions[:i+1, 1])\n",
    "    scat.set_offsets([positions[i, 0], positions[i, 1]])\n",
    "    plt.draw()\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=n_steps+1, interval=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optymalizatory (10m)\n",
    "Optymalizatory pozwalają na bardziej skomplikowane mechanizmy zmiany parametrów np. poprzez zachowanie momentu. Naczęściej używane Adam, RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "from matplotlib import animation\n",
    "import torch\n",
    "\n",
    "n_steps = 10\n",
    "x_lin = torch.linspace(-2, 2, 1000)\n",
    "y_lin = torch.linspace(-2, 2, 1000)\n",
    "x, y = torch.meshgrid(x_lin, y_lin)\n",
    "\n",
    "def func(x, y):\n",
    "    return x**2 - y**2\n",
    "\n",
    "optimizers_cls = [\n",
    "    torch.optim.SGD,\n",
    "    torch.optim.Adam,\n",
    "    torch.optim.RMSprop\n",
    "]\n",
    "\n",
    "theta_init = torch.rand((2)) * 2 - 1\n",
    "optim_theta = [theta_init.clone().requires_grad_() for _ in optimizers_cls]\n",
    "optimizers = [opti_cls([theta], lr=0.1) for theta, opti_cls in zip(optim_theta, optimizers_cls)]\n",
    "positions = torch.zeros((len(optimizers_cls), n_steps+1, 2))\n",
    "\n",
    "# Training loop\n",
    "positions[:, 0] = theta_init.detach()\n",
    "\n",
    "\n",
    "for epoch in range(n_steps):\n",
    "    for i, (opti, theta) in enumerate(zip(optimizers, optim_theta)):\n",
    "        opti.zero_grad()\n",
    "        output = -1 * func(theta[0], theta[1])\n",
    "        output.backward()\n",
    "        opti.step()\n",
    "        positions[i, epoch+1] = theta.detach()\n",
    "\n",
    "# Animation of SGD steps\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "scat = [None] * len(optimizers)\n",
    "line = [None] * len(optimizers)\n",
    "for i, opti in enumerate(optimizers):\n",
    "    scat[i] = ax.scatter(positions[i, 0, 0], positions[i, 0, 1])\n",
    "    line[i], = ax.plot(positions[i, 0, 0], positions[i, 0, 1], label=opti)\n",
    "\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.imshow(func(x, y), extent=[-2, 2, 2, -2])\n",
    "\n",
    "def animate(frame):\n",
    "    for i, _ in enumerate(optimizers):\n",
    "        line[i].set_data(positions[i, :frame+1, 0], positions[i, :frame+1, 1])\n",
    "        scat[i].set_offsets([positions[i, frame, 0], positions[i, frame, 1]])\n",
    "    plt.draw()\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, frames=n_steps+1, interval=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje aktywacji (5m)\n",
    "Funkcje aktywacji określają wyściowy poziom aktywacji neuronu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liniowa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def relu_activation(x):\n",
    "    return x\n",
    "\n",
    "inputs = np.linspace(-10, 10, 50)\n",
    "outputs = np.vectorize(relu_activation)(inputs)\n",
    "\n",
    "plt.plot(inputs, outputs)\n",
    "plt.title('Liniowa funkcja aktywacji')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoida\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def relu_activation(x):\n",
    "    return 1 / (1 + np.e ** -x)\n",
    "\n",
    "inputs = np.linspace(-10, 10, 50)\n",
    "outputs = np.vectorize(relu_activation)(inputs)\n",
    "\n",
    "plt.plot(inputs, outputs)\n",
    "plt.title('Sigmoidalna funkcja aktywacji')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def relu_activation(x):\n",
    "    return x if x >= 0.0 else 0.0\n",
    "\n",
    "inputs = np.linspace(-10, 10, 51)\n",
    "outputs_relu = np.vectorize(relu_activation)(inputs)\n",
    "\n",
    "plt.plot(inputs, outputs_relu)\n",
    "plt.title('Rectifier Linear Unit')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "scores = np.array([3.0, 1.0, 0.2])\n",
    "print(softmax(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje straty (10m)\n",
    "\n",
    "* Regresja\n",
    "  * MSE - średni błąd kwadratowy $1/n * \\sum{(x - y) ^ 2}$\n",
    "  * MAE - średni błąd absolutny $1/n * \\sum{|x - y|}$\n",
    "\n",
    "* Klasyfikacja\n",
    "  * CE - cross entropy  $-\\sum_{c=1}^My_{o,c}\\log(p_{o,c})$ gdzie M to liczba klas\n",
    "  * NLL - negative loglikelihood $NLL(y) = -{\\log(p(y))}$\n",
    "  * KL divergence - Kullback-Leibler Divergence $KL(\\hat{y} || y) = \\sum_{c=1}^{M}\\hat{y}_c \\log{\\frac{\\hat{y}_c}{y_c}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbudujmy własną sieć (15m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "  def __init__(self, input_dim: int, num_hidden: int = 1):\n",
    "    self.weights = np.random.randn(input_dim, num_hidden) * np.sqrt(2. / input_dim)\n",
    "    self.bias = np.zeros(num_hidden)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.x = x\n",
    "    output = x @ self.weights + self.bias\n",
    "    return output\n",
    "\n",
    "  def backward(self, gradient, lr):\n",
    "    # Calculate gradients\n",
    "    self.weights_gradient = self.x.T @ gradient\n",
    "    self.bias_gradient = np.sum(gradient, axis=0)\n",
    "    self.x_gradient = gradient @ self.weights.T\n",
    "\n",
    "    # Apply update\n",
    "    self.weights = self.weights - lr * self.weights_gradient\n",
    "    self.bias = self.bias - lr * self.bias_gradient\n",
    "    return self.x_gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE:\n",
    "  def __call__(self, y_pred, y_true):\n",
    "    self.y_pred = y_pred\n",
    "    self.y_true = y_true\n",
    "    return np.mean((y_pred - y_true) ** 2)\n",
    "\n",
    "  def backward(self):\n",
    "    n = self.y_true.shape[0]\n",
    "    self.gradient = 2. * (self.y_pred - self.y_true) / n\n",
    "    return self.gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, layers: list):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def backward(self, gradient, lr):\n",
    "        for layer in self.layers[::-1]:\n",
    "            gradient = layer.backward(gradient, lr)\n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_3d(x, y, y_pred=None):\n",
    "  fig = plt.figure()\n",
    "  ax = fig.add_subplot(111, projection='3d')\n",
    "  ax.scatter(x[:, 0], x[:, 1], y, label='base function')\n",
    "  if y_pred is not None:\n",
    "    ax.scatter(x[:, 0], x[:, 1], y_pred, label='our function')\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generacja liniowego datasetu\n",
    "sample_size = 100\n",
    "dimensions = 2\n",
    "x = np.random.uniform(-1.0, 1.0, (sample_size, dimensions))\n",
    "\n",
    "weights = np.array([[4, -1]]).T\n",
    "bias = np.array([0.5])\n",
    "y = x @ weights + bias\n",
    "plot_3d(x, y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "lr = 0.1\n",
    "model = Model([\n",
    "    Linear(2)\n",
    "])\n",
    "loss = MSE()\n",
    "\n",
    "plot_3d(x, y[:, 0], model(x)[:, 0])\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_pred = model(x)\n",
    "    loss_val = loss(y_pred, y)\n",
    "    gradient_from_loss = loss.backward()\n",
    "    model.backward(gradient_from_loss, lr)\n",
    "    print(loss_val)\n",
    "\n",
    "plot_3d(x, y[:, 0], model(x)[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generacja nie liniowego datasetu\n",
    "sample_size = 100\n",
    "dimensions = 2\n",
    "x = np.random.uniform(-1.0, 1.0, (sample_size, dimensions))\n",
    "\n",
    "a = np.array([[7, -1]]).T\n",
    "b = np.array([[3, 1]]).T\n",
    "bias = np.array([7])\n",
    "y = (x ** 2) @ a + x @ b + bias\n",
    "plot_3d(x, y[:, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "lr = 0.1\n",
    "model = Model([\n",
    "    Linear(2)\n",
    "])\n",
    "loss = MSE()\n",
    "\n",
    "plot_3d(x, y[:, 0], model(x)[:, 0])\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_pred = model(x)\n",
    "    loss_val = loss(y_pred, y)\n",
    "    gradient_from_loss = loss.backward()\n",
    "    model.backward(gradient_from_loss, lr)\n",
    "    print(loss_val)\n",
    "\n",
    "plot_3d(x, y[:, 0], model(x)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __call__(self, input_):\n",
    "        self.input_ = input_\n",
    "        self.output = np.clip(self.input_, 0, None)\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_gradient, _):\n",
    "      self.input_gradient = (self.input_ > 0) * output_gradient\n",
    "      return self.input_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      2\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m([\n\u001b[1;32m      4\u001b[0m     Linear(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      5\u001b[0m     ReLU(),\n\u001b[1;32m      6\u001b[0m     Linear(\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m      7\u001b[0m ])\n\u001b[1;32m      8\u001b[0m loss \u001b[38;5;241m=\u001b[39m MSE()\n\u001b[1;32m     10\u001b[0m plot_3d(x, y[:, \u001b[38;5;241m0\u001b[39m], model(x)[:, \u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Model' is not defined"
     ]
    }
   ],
   "source": [
    "num_epoch = 100\n",
    "lr = 0.1\n",
    "model = Model([\n",
    "    Linear(2, 2),\n",
    "    ReLU(),\n",
    "    Linear(2),\n",
    "])\n",
    "loss = MSE()\n",
    "\n",
    "plot_3d(x, y[:, 0], model(x)[:, 0])\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_pred = model(x)\n",
    "    loss_val = loss(y_pred, y)\n",
    "    gradient_from_loss = loss.backward()\n",
    "    model.backward(gradient_from_loss, lr)\n",
    "    print(loss_val)\n",
    "\n",
    "plot_3d(x, y[:, 0], model(x)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __call__(self, input):\n",
    "        self.output =  1 / (1  + np.exp(-input))\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, output_gradient, _):\n",
    "      return output_gradient *self.output * (1-self.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "lr = 0.1\n",
    "model = Model([\n",
    "    Linear(2, 2),\n",
    "    Sigmoid(),\n",
    "    Linear(2),\n",
    "])\n",
    "loss = MSE()\n",
    "\n",
    "plot_3d(x, y[:, 0], model(x)[:, 0])\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    y_pred = model(x)\n",
    "    loss_val = loss(y_pred, y)\n",
    "    gradient_from_loss = loss.backward()\n",
    "    model.backward(gradient_from_loss, lr)\n",
    "    print(loss_val)\n",
    "\n",
    "plot_3d(x, y[:, 0], model(x)[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ankieta\n",
    "![\"Ankieta\"](./ankieta.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dodatkowe linki\n",
    "[Wizualizacja algorytmow optymalizacji](https://imgur.com/a/visualizing-optimization-algos-Hqolp#NKsFHJb)  \n",
    "[Wizualizacja crossentropy i loglikelihood](https://towardsdatascience.com/cross-entropy-negative-log-likelihood-and-all-that-jazz-47a95bd2e81)  \n",
    "[3Blue1Brown - propagacja wsteczna](https://www.youtube.com/watch?v=tIeHLnjs5U8)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
